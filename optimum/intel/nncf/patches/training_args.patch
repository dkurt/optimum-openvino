diff --git a/training_args.py b/training_args.py
index 85abc7f..c621c28 100644
--- a/training_args.py
+++ b/training_args.py
@@ -677,6 +677,9 @@ class TrainingArguments:
         metadata={"help": "Used by the SageMaker launcher to send mp-specific args. Ignored in Trainer"},
     )

+    nncf_config: str = field(default=None,
+                             metadata={"help": "NNCF configuration .json file for compression-enabled training"})
+
     def __post_init__(self):
         # Handle --use_env option in torch.distributed.launch (local_rank not passed as an arg then).
         # This needs to happen before any call to self.device or self.n_gpu.
